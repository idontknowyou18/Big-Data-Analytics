{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03 Partitioned Datasets.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPNsqTcYk5oV+PSXPPFrT1H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/revendrat/Big-Data-Analytics/blob/main/03_Partitioned_Datasets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Writing partitioned data sets\n",
        "* Arrow allows you to split big dataset into multiple separate files using pyarrow.dataset.write_dataset()\n",
        "* The partitioning argument specifies particular column to split on pyarrow.dataset.write_dataset() function.\n",
        "\n",
        "## Illustration\n",
        "* 1000 individuals birthdays from 2010 to 2019\n"
      ],
      "metadata": {
        "id": "VfF508iMz27p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "E6WECSBpzSfH"
      },
      "outputs": [],
      "source": [
        "import numpy.random\n",
        "import pyarrow as pa\n",
        "data = pa.table({\"day\": numpy.random.randint(1, 31, size=1000),\n",
        "                 \"month\": numpy.random.randint(1, 12, size=1000),\n",
        "                 \"year\": [2010 + x // 100 for x in range(1000)]})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxZtAJW30w-y",
        "outputId": "1962c942-5773-4720-ce0e-f9589b7d9586"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyarrow.Table\n",
              "day: int64\n",
              "month: int64\n",
              "year: int64\n",
              "----\n",
              "day: [[9,21,12,29,19,13,6,25,7,23,...,10,22,4,3,19,28,10,19,19,21]]\n",
              "month: [[5,8,10,10,4,5,5,6,5,10,...,10,1,2,1,5,10,9,10,5,7]]\n",
              "year: [[2010,2010,2010,2010,2010,2010,2010,2010,2010,2010,...,2019,2019,2019,2019,2019,2019,2019,2019,2019,2019]]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyarrow.dataset as ds\n",
        "# partition by year column\n",
        "ds.write_dataset(data, \"./partitioned\", format=\"parquet\",\n",
        "                 partitioning=ds.partitioning(pa.schema([(\"year\", pa.int16())])))"
      ],
      "metadata": {
        "id": "3-ev2ek60_TO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMtSNnU42i9B",
        "outputId": "962dde8a-1b6a-4da1-bda3-31595435eea4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "partitioned  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the partitioned directory\n",
        "from pyarrow import fs\n",
        "\n",
        "localfs = fs.LocalFileSystem()\n",
        "partitioned_dir_content = localfs.get_file_info(fs.FileSelector(\"./partitioned\", recursive=True))\n",
        "files = sorted((f.path for f in partitioned_dir_content if f.type == fs.FileType.File))\n",
        "\n",
        "for file in files:\n",
        "    print(file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UiULos52j3Q",
        "outputId": "4f24b2d7-bd3e-489c-ddba-50552e8a4d4e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "./partitioned/2010/part-0.parquet\n",
            "./partitioned/2011/part-0.parquet\n",
            "./partitioned/2012/part-0.parquet\n",
            "./partitioned/2013/part-0.parquet\n",
            "./partitioned/2014/part-0.parquet\n",
            "./partitioned/2015/part-0.parquet\n",
            "./partitioned/2016/part-0.parquet\n",
            "./partitioned/2017/part-0.parquet\n",
            "./partitioned/2018/part-0.parquet\n",
            "./partitioned/2019/part-0.parquet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reading Partitioned data\n",
        "* In case dataset is composed by multiple separate files each containing a piece of the data.\n",
        "* The pyarrow.dataset.dataset() function provides an interface to discover and read all those files as a single big dataset."
      ],
      "metadata": {
        "id": "WDmPADY24CWJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# View the files\n",
        "dataset = ds.dataset(\"./partitioned\", format=\"parquet\")\n",
        "print(dataset.files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Q2nK_zZ2uyW",
        "outputId": "f4d1c73b-8edb-48ae-e82d-16c1f6984ba3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['./partitioned/2010/part-0.parquet', './partitioned/2011/part-0.parquet', './partitioned/2012/part-0.parquet', './partitioned/2013/part-0.parquet', './partitioned/2014/part-0.parquet', './partitioned/2015/part-0.parquet', './partitioned/2016/part-0.parquet', './partitioned/2017/part-0.parquet', './partitioned/2018/part-0.parquet', './partitioned/2019/part-0.parquet']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The whole dataset can be viewed as a single big table using pyarrow.dataset.Dataset.to_table(). \n",
        "* While each parquet file contains only 10 rows, converting the dataset to a table will expose them as a single Table."
      ],
      "metadata": {
        "id": "FPU63uqQ4_EP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the data from partitioned files\n",
        "table = dataset.to_table()\n",
        "print(table)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DA5MaLYB3tP7",
        "outputId": "776ba1b3-aa6a-43b3-882c-aff0ae8c2f40"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pyarrow.Table\n",
            "day: int64\n",
            "month: int64\n",
            "----\n",
            "day: [[9,21,12,29,19,13,6,25,7,23,...,8,11,2,6,22,27,5,26,16,22],[26,15,20,22,12,26,22,24,23,21,...,19,7,3,1,25,29,7,8,20,12],[27,17,9,8,24,21,24,9,10,1,...,28,8,13,23,5,18,18,28,21,1],[16,13,12,30,21,3,17,22,12,21,...,10,30,16,6,12,11,7,25,30,28],[20,29,11,6,30,4,3,14,14,14,...,25,17,30,24,10,12,28,25,23,12],[20,3,25,3,25,29,7,18,5,21,...,22,29,16,27,21,4,9,2,27,11],[11,5,23,1,16,1,17,8,10,24,...,13,3,21,1,3,26,19,18,11,28],[30,27,27,1,29,22,25,25,6,7,...,25,4,6,1,10,14,27,19,11,20],[8,2,1,10,28,10,16,21,17,13,...,6,1,15,10,5,20,9,20,12,1],[22,6,9,30,8,11,5,27,20,27,...,10,22,4,3,19,28,10,19,19,21]]\n",
            "month: [[5,8,10,10,4,5,5,6,5,10,...,11,2,4,11,10,1,4,5,9,6],[6,3,10,4,4,1,10,3,11,8,...,4,5,6,5,5,3,7,2,6,10],[8,11,11,3,9,5,1,3,6,4,...,5,9,11,11,8,10,6,5,3,4],[9,7,4,5,1,8,9,5,1,2,...,1,6,6,6,9,4,3,5,6,1],[8,11,6,5,9,9,5,4,1,5,...,3,10,10,1,10,8,10,10,8,1],[11,6,9,10,5,3,5,9,9,4,...,3,4,11,7,10,8,8,11,8,1],[7,8,4,9,8,4,10,8,11,5,...,4,9,6,7,8,8,11,8,6,10],[4,1,3,9,9,6,3,7,4,8,...,6,8,8,6,11,5,10,11,8,10],[9,1,9,9,9,3,9,2,7,5,...,10,7,7,11,8,11,2,2,4,3],[11,8,1,6,6,10,8,4,1,3,...,10,1,2,1,5,10,9,10,5,7]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Batches: Limitation of converting data files to pyarrow.Table\n",
        "* Entire data will be loaded into memory\n",
        "* A lot of memory will be occupied, instead use batches\n",
        "* pyarrow.dataset.Dataset.to_batches() method iteratively loads the dataset one chunk of data at the time returning a pyarrow.RecordBatch for each one of them."
      ],
      "metadata": {
        "id": "ma95iT3u6b-i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = ds.dataset(\"./partitioned\", format=\"parquet\")\n",
        "print(dataset.files)\n",
        "\n",
        "for record_batch in dataset.to_batches():\n",
        "    col_day = record_batch.column(\"day\")\n",
        "    col_mon = record_batch.column(\"month\")\n",
        "    print(f\"{col_day._name} = {col_day[0]} .. {col_day[-1]}\")\n",
        "    print(f\"{col_mon._name} = {col_mon[0]} .. {col_mon[-1]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHhqa8R05K5Q",
        "outputId": "d09856c7-83fa-48df-ba2b-c2e8cb5769cb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['./partitioned/2010/part-0.parquet', './partitioned/2011/part-0.parquet', './partitioned/2012/part-0.parquet', './partitioned/2013/part-0.parquet', './partitioned/2014/part-0.parquet', './partitioned/2015/part-0.parquet', './partitioned/2016/part-0.parquet', './partitioned/2017/part-0.parquet', './partitioned/2018/part-0.parquet', './partitioned/2019/part-0.parquet']\n",
            "day = 9 .. 22\n",
            "month = 5 .. 6\n",
            "day = 26 .. 12\n",
            "month = 6 .. 10\n",
            "day = 27 .. 1\n",
            "month = 8 .. 4\n",
            "day = 16 .. 28\n",
            "month = 9 .. 1\n",
            "day = 20 .. 12\n",
            "month = 8 .. 1\n",
            "day = 20 .. 11\n",
            "month = 11 .. 1\n",
            "day = 11 .. 28\n",
            "month = 7 .. 10\n",
            "day = 30 .. 20\n",
            "month = 4 .. 10\n",
            "day = 8 .. 1\n",
            "month = 9 .. 3\n",
            "day = 22 .. 21\n",
            "month = 11 .. 7\n"
          ]
        }
      ]
    }
  ]
}